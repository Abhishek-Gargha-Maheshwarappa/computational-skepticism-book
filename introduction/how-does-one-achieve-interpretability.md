# How does one achieve interpretability?

There are no clear measures for measuring interpretability but there has been a lot of progress in this field. Google AI recently innovated TCAV which allows an individual to test a model on concepts it has generated through training. Microsoft has also been keeping up to trends with Azure Machine Learning Studio. Azure ML empowers developers and data scientists to make models and interpret them with great visualization tools, all on the cloud! While companies continuously work to make innovative technological advancements in this field, traditional methods continue to provide a good base with model interpretation. These methods include Global surrogates, Feature interaction, PDPs, Shapley, LIME, etc.  In this book, we will give a "hands-on" with a few of these methods, namely - OLS, AzureML, LIME, SHAP and TCAV. We have taken multiple datasets to interpret and code in python to demonstrate how to achieve interpretability. 

