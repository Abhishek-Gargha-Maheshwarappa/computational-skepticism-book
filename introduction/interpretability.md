# Interpretability vs Explainability

Human decisions are being pushed to be made by Machine Learning models. Human decisions generally tend to depend on beliefs and values, and sometimes on habit or tradition. Whatever the case, every human decision has a justification. Therefore, if we are to replace human decisions by a model's decision, it is highly important to be able to understand these model decisions, just like human's decisions are justified.

How would we define interpretability in daily life? "Interpretability" is not a term one would find in the dictionary, but if we split the word, we can get a sense of the meaning - "Interpret-ability". Just by looking at this, one can tell that this refers to the ability to interpret something. 

Take the example of applications to companies for a job or university applications for a study program - the rejection is often not explained. If we get accepted, however, we interpret that our skills and experience match the expectations of the approving personnel, but we still do not know the exact metrics that got us the approval. The explanations behind such a decision could be highly useful but are not entirely necessary. The explanation can help an individual to work on the required skills and improve their chances of getting that dream job, or even help to get acceptance from a prestigious university. A simple "Interpretation" of the result gives us confidence about the decision. When we interpret, we make a comparison to understand. So, if a person wanted to study at MIT, he/she would connect with other students that got admission and compare their profiles to themselves. 

![](../.gitbook/assets/image%20%2888%29.png)

This is the difference between interpretations and explanations. Many times we do not know the explanation of a decision but have a good interpretation. Similarly, for machine learning models, which are like black-box models for most of the audience, the explanation is something that gives full clarity into what happened and why. But interpretation also serves the purpose of understanding a decision and is way less expensive computationally. 

It is important to have a clear understanding of the difference between these terms since this book only focuses on achieving the "Interpretability" of black-box models.

![](../.gitbook/assets/image%20%28105%29.png)

