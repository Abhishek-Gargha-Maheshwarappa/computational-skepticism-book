# Methods of Model Interpretability

Before taking about the different methods for model interpretability, need to mention the type of machine learning models. 

There are two types models 

1. Interpretable Models
2. Black Box Models

Interpretable Models are interpretable in itself, they don't require any other method to explain them explicitly. The other interpretable methods can be employed to them also for interpreting the model.  

This book discusses three interpretable models 

1. Linear regression
2. Logistic regression
3. Decision Tree

Black Box Models are those which are not interpretable in itself, they require other methods to explain them. The reason why these models are called the black-box model because they are least understood or they are very complex to understand or not understood at all. For example, when we consider the neural network model there are millions of weights and calculations that are happening within these layers, and to understand them is either very difficult or not possible for the human mind to understand such large calculations. Hence these models are called Black Models.



