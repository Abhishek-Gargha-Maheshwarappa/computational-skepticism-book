# Methods of Model Interpretability

Before taking about the different methods for model interpretability, need to mention the type of machine learning models. 

There are two types models 

1. Interpretable Models
2. Black Box Models

Interpretable Models are interpretable in itself, they don't require any other method to explain them explicitly. The other interpretable methods can be employed to them also for interpreting the model.  

This book discusses three interpretable models 

1. Linear regression
2. Logistic regression
3. Decision Tree

Black Box Models are those which are not interpretable in itself, they require other methods to explain them. The reason why these models are called the black-box model because they are least understood or they are very complex to understand or not understood at all. For example, when we consider the neural network model there are millions of weights and calculations that are happening within these layers, and to understand them is either very difficult or not possible for the human mind to understand such large calculations. Hence these models are called Black Models.

**Methods of Interpretability**

There are three methods employed for achieving model interpretability‌

1. Interpretable machine models
2. Model agonistic methods
3. Model-specific methods

**Interpretable machine models:** These are models which are interpretable by themselves, without external methods. Example - Linear regression and Decision trees 

**Model agonistic methods:** These are the methods that can be employed to interpret any models. Example - SHAP, LIME and PDP

**‌Model-specific methods:** These are the methods that can be employed to specific models.

