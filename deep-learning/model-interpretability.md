# Model Interpretability

The deep learning models are difficult to interpret compared to the linear models. To interpret the deep learning let us consider an example of convolution neural network for the classification of the image.   
****

### **SHAP \(SHapley Additive exPlanations\)** 

It is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic  


