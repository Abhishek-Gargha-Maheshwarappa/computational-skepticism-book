---
description: Model that are interpretable implicitly and industrial applications
---

# Interpretable Machine learning models

In this section of the book, we want to discuss in detail about some directly Interpretable machine learning models. These are simple models that are widely used in many applications all around us. We will be diving deep into the model explanation for these simple models. 

Consider an example of when you buy a toaster - it is self-explanatory in itself about how it should be used and there will be no need for another person to explain how to operate the toaster. The same is the case with Interpretable machine learning models. They are naturally easy to understand and interpret. 

![](../.gitbook/assets/image%20%28103%29.png)

This book discusses two interpretable models 

1. Linear regression
2. Decision Tree

Every machine learning engineer or data scientist learns these two models in the start of their career and every course work will contain these two machine learning models as the fundamental models. The rationale behind this is they are easy to understand and learn from. These models make sense and people can easily connect them with their daily life.

![](../.gitbook/assets/image%20%28107%29.png)

These were some simple examples of interpretable models. There are cases where simple interpretable machine learning models fail to give self-explanation. For example, when there is multi-collinearity or when there is an interaction effect among the features, the linear models fail to explain themselves  and might need the help of some other methods to be made interpretable. In the next sections, we will explain in detail what multi-collinearity and interaction effect is. We will also explain how Linear models and Decision Trees are interpretable and move on to other techniques to achieve interpretability in the later parts of this book.

